# Reflection on Buolamwini's "Unmasking AI"

Reading "Unmasking AI" has profoundly shifted my perspective on the intersection of technology and social responsibility, especially as I reflect on my own journey in AI development and research. Three aspects of the book really related to me:

- Our struggles with healthcare AI
- The ethical challenges in LLM development 
- My perspective as an international student in tech

## The Cost of Algorithmic Blindness in Healthcare

When I worked on that Kaggle competition for melanoma classification, we kept running into this frustrating problem - our models just weren't working well for darker skin samples. Reading about Buolamwini's experiences with facial recognition bias made me reflect our own work. It wasn't just about losing a competition; we were dealing with something that could affect real people's lives. A misclassified melanoma could mean delayed treatment, unnecessary procedures, or potential life-threatening consequences for a patient whose data is not representative in the trianing database. That's the kind of real-world impact Buolamwini keeps emphasizing throughout her book.

## Facing the Coded Gaze in Language Models

Working as an LLM engineer, I have started seeing these bias issues everywhere. During my final project on AIPI590 Alternative Data Sourcing, I was surprised - but maybe shouldn't have been - when people were more interested in discussing ethical problem in social media data than the technical aspects. Buolamwini's concept of the "coded gaze" really makes me think twice about every model I help build now.

## Breaking the Alabaster: A Personal Resonance

As an international student, I found myself nodding along with Buolamwini's experiences as a minority studying in US. Her persistence despite all the challenges she faced is inspiring. She turned her personal experiences into a force for positive change - that's exactly the kind of impact I hope to have in my own career in the tech areas.

## Beyond Metrics: Our Real Responsibility

The book has really opened my eyes to our responsibility as AI practitioners. It's not just about achieving good metrics anymore; we need to think about who our systems might be leaving behind or even harming. In healthcare especially, where I have done some work, these aren not just machine learning modeling problems - they're literally matters of life and death.